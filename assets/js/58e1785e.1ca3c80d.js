"use strict";(self.webpackChunkcashew_da_docs=self.webpackChunkcashew_da_docs||[]).push([[231],{1249:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>o,contentTitle:()=>i,default:()=>h,frontMatter:()=>r,metadata:()=>a,toc:()=>d});var t=s(5893),l=s(1151);const r={},i=void 0,a={id:"Models/U_Net",title:"U_Net",description:"Brief description of the submodule",source:"@site/docs/Models/U_Net.md",sourceDirName:"Models",slug:"/Models/U_Net",permalink:"/CashewDA-docs/docs/Models/U_Net",draft:!1,unlisted:!1,editUrl:"https://github.com/${organizationName}/${projectName}/tree/main/docs/Models/U_Net.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Loss_Functions",permalink:"/CashewDA-docs/docs/Models/Loss_Functions"},next:{title:"Training",permalink:"/CashewDA-docs/docs/category/training"}},o={},d=[{value:"Brief description of the submodule",id:"brief-description-of-the-submodule",level:2},{value:"Major blocks",id:"major-blocks",level:2},{value:"FE",id:"fe",level:3},{value:"Attributes",id:"attributes",level:4},{value:"Methods",id:"methods",level:4},{value:"Source code",id:"source-code",level:4},{value:"C",id:"c",level:3},{value:"Attributes",id:"attributes-1",level:4},{value:"Methods",id:"methods-1",level:4},{value:"Source code",id:"source-code-1",level:4},{value:"D",id:"d",level:3},{value:"Attributes",id:"attributes-2",level:4},{value:"Methods",id:"methods-2",level:4},{value:"Source code",id:"source-code-2",level:4},{value:"Networks implemented",id:"networks-implemented",level:2},{value:"UNet",id:"unet",level:3},{value:"Overview",id:"overview",level:4},{value:"Attributes",id:"attributes-3",level:4},{value:"Methods",id:"methods-3",level:4},{value:"Source code",id:"source-code-3",level:4},{value:"UNetDANN",id:"unetdann",level:3},{value:"Overview",id:"overview-1",level:4},{value:"Attributes",id:"attributes-4",level:4},{value:"Methods",id:"methods-4",level:4},{value:"Source code",id:"source-code-4",level:4}];function c(e){const n={a:"a",annotation:"annotation",code:"code",em:"em",h2:"h2",h3:"h3",h4:"h4",img:"img",li:"li",math:"math",mi:"mi",mn:"mn",mrow:"mrow",mtext:"mtext",p:"p",pre:"pre",semantics:"semantics",span:"span",strong:"strong",ul:"ul",...(0,l.a)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h2,{id:"brief-description-of-the-submodule",children:"Brief description of the submodule"}),"\n",(0,t.jsxs)(n.p,{children:["This submodule uses the building blocks from ",(0,t.jsx)(n.a,{href:"./buildingblocks",children:"Buildingblocks"})," to first build major blocks which consist of:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"FE:"})," The feature extractor"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"C:"})," The classifier head of the ",(0,t.jsx)(n.a,{href:"#unet",children:"U-Net"})," and"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"D:"})," The discriminator head of the ",(0,t.jsx)(n.a,{href:"#unetdann",children:"U-Net + DANN"}),"."]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["And secondly build the models used for segmentation ",(0,t.jsx)(n.a,{href:"#unet",children:"U-Net"})," and domain adaptation purposes (",(0,t.jsx)(n.a,{href:"#unetdann",children:"U-Net + DANN"}),")."]}),"\n",(0,t.jsx)(n.h2,{id:"major-blocks",children:"Major blocks"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Major blocks",src:s(7549).Z+"",width:"1003",height:"621"})}),"\n",(0,t.jsx)(n.h3,{id:"fe",children:"FE"}),"\n",(0,t.jsx)(n.p,{children:"Class containing the layers considered for the extraction of features from the 2D images."}),"\n",(0,t.jsx)(n.p,{children:"This feature extractor can change its size depending on the layer in which it is decided to divide the U-Net into feature extractor and classifier."}),"\n",(0,t.jsxs)(n.p,{children:["The division of the U-Net was inspired by the implementation done by ",(0,t.jsx)(n.a,{href:"https://www.sciencedirect.com/science/article/pii/S0010482521000639?via%3Dihub",children:"brion et al. (2019)"})," for domain adaptation in 3D medical imagery."]}),"\n",(0,t.jsx)(n.h4,{id:"attributes",children:"Attributes"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"self.n_channels:"})," (int) Number of channels [bands] on the images that will enter the network."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"self.starter:"})," (int) Number of feature maps obtained from the first double convolution performed. The number of feature maps obtained for every double convolution will be then calculated multiplying this value by ",(0,t.jsxs)(n.span,{className:"katex",children:[(0,t.jsx)(n.span,{className:"katex-mathml",children:(0,t.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,t.jsxs)(n.semantics,{children:[(0,t.jsxs)(n.mrow,{children:[(0,t.jsx)(n.mn,{children:"2"}),(0,t.jsx)(n.mtext,{children:"\u02c6"}),(0,t.jsx)(n.mi,{children:"n"})]}),(0,t.jsx)(n.annotation,{encoding:"application/x-tex",children:"2\u02c6n"})]})})}),(0,t.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,t.jsxs)(n.span,{className:"base",children:[(0,t.jsx)(n.span,{className:"strut",style:{height:"0.6944em"}}),(0,t.jsx)(n.span,{className:"mord",children:"2\u02c6"}),(0,t.jsx)(n.span,{className:"mord mathnormal",children:"n"})]})})]}),", where ",(0,t.jsxs)(n.span,{className:"katex",children:[(0,t.jsx)(n.span,{className:"katex-mathml",children:(0,t.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,t.jsxs)(n.semantics,{children:[(0,t.jsx)(n.mrow,{children:(0,t.jsx)(n.mi,{children:"n"})}),(0,t.jsx)(n.annotation,{encoding:"application/x-tex",children:"n"})]})})}),(0,t.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,t.jsxs)(n.span,{className:"base",children:[(0,t.jsx)(n.span,{className:"strut",style:{height:"0.4306em"}}),(0,t.jsx)(n.span,{className:"mord mathnormal",children:"n"})]})})]})," is the level in the U_net, starting from 0 in the upmost layer and 2 in the lowest layer."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"self.up_layer:"})," (int : [0-4]) Number indicating the layer in which the network is divided into Feature Extractor and Classifier."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"self.bilinear:"})," (Boolean) Boolean indicating the method for upsampling in the expanding path. ",(0,t.jsx)(n.em,{children:"Default"})," is True."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"self.attention:"})," (Boolean) Boolean to indicate if attention gates will be added on the upsampling step. ",(0,t.jsx)(n.em,{children:"Default"})," is False."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"self.resunet:"})," (Boolean) Boolean used to indicate if the double convolution will have a residual connection or not. ",(0,t.jsx)(n.em,{children:"Default"})," is False."]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"methods",children:"Methods"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"DownSteps:"})," Function to get the resulting feature maps of each of the steps performed on the contracting path of the U-Net."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"forward:"})," Function to perform the forward calculation of the features extracted."]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"source-code",children:"Source code"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'class FE(nn.Module):\n    """\n      Class for the creation of the feature extractor.\n    """\n    def __init__(self, n_channels, starter, up_layer, bilinear = True, attention = False, resunet = False):\n        super(FE, self).__init__()\n\n        self.n_channels = n_channels\n        self.starter = starter\n        self.bilinear = bilinear \n        self.up_layer = up_layer\n        self.attention = attention\n        self.resunet = resunet\n\n        # Layers related to segmentation task\n        self.inc = (DoubleConv(self.n_channels, self.starter, resunet = self.resunet))\n        self.down1 = (Down(self.starter, self.starter*(2**1), resunet = self.resunet))\n        self.down2 = (Down(self.starter*(2**1), self.starter*(2**2), resunet = self.resunet))\n        self.down3 = (Down(self.starter*(2**2), self.starter*(2**3), resunet = self.resunet))\n    \n        factor = 2 if bilinear else 1\n        \n        self.down4 = (Down(self.starter*(2**3), self.starter*(2**4) // factor, resunet = self.resunet))\n        \n        if self.up_layer >= 1:\n            self.up1 = (Up(self.starter*(2**4), self.starter*(2**3) // factor, bilinear, attention, resunet = self.resunet))\n        if self.up_layer >= 2:\n            self.up2 = (Up(self.starter*(2**3), self.starter*(2**2) // factor, bilinear, attention, resunet = self.resunet))\n        if self.up_layer >= 3:\n            self.up3 = (Up(self.starter*(2**2), self.starter*(2**1) // factor, bilinear, attention, resunet = self.resunet))\n        if self.up_layer >= 4:\n            self.up4 = (Up(self.starter*(2**1), self.starter, bilinear, attention, resunet = self.resunet))\n\n    def DownSteps(self, x):\n\n        x1 = self.inc(x)\n        x2 = self.down1(x1)\n        x3 = self.down2(x2)\n        x4 = self.down3(x3)\n        x5 = self.down4(x4)\n\n        return x1, x2, x3, x4, x5\n\n    def forward(self, x):\n\n        # Downsample steps\n        x1, x2, x3, x4, x5 = self.DownSteps(x)\n\n        # Upsample steps\n        if self.up_layer == 0:\n            x = x5\n        if self.up_layer >= 1:\n            x = self.up1(x5, x4)\n        if self.up_layer >= 2:\n            x = self.up2(x, x3)\n        if self.up_layer >= 3:\n            x = self.up3(x, x2)\n        if self.up_layer >= 4:\n            x = self.up4(x, x1)\n\n        return x\n'})}),"\n",(0,t.jsx)(n.h3,{id:"c",children:"C"}),"\n",(0,t.jsxs)(n.p,{children:["Class containing the layers considered for the segmentation of the 2D images using the features extracted from ",(0,t.jsx)(n.a,{href:"##FE",children:"FE"})]}),"\n",(0,t.jsx)(n.p,{children:"This classifier can change its size depending on the layer in which it is decided to divide the U-Net into feature extractor and classifier."}),"\n",(0,t.jsxs)(n.p,{children:["The division of the U-Net was inspired by the implementation done by ",(0,t.jsx)(n.a,{href:"https://www.sciencedirect.com/science/article/pii/S0010482521000639?via%3Dihub",children:"brion et al. (2019)"})," for domain adaptation in 3D medical imagery."]}),"\n",(0,t.jsx)(n.h4,{id:"attributes-1",children:"Attributes"}),"\n",(0,t.jsx)(n.p,{children:"==NEED TO REMOVE N_CHANNELS AS ATTRIBUTE =="}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"self.starter:"})," (int) Number of feature maps obtained from the first double convolution performed. The number of feature maps obtained for every double convolution will be then calculated multiplying this value by ",(0,t.jsxs)(n.span,{className:"katex",children:[(0,t.jsx)(n.span,{className:"katex-mathml",children:(0,t.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,t.jsxs)(n.semantics,{children:[(0,t.jsxs)(n.mrow,{children:[(0,t.jsx)(n.mn,{children:"2"}),(0,t.jsx)(n.mtext,{children:"\u02c6"}),(0,t.jsx)(n.mi,{children:"n"})]}),(0,t.jsx)(n.annotation,{encoding:"application/x-tex",children:"2\u02c6n"})]})})}),(0,t.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,t.jsxs)(n.span,{className:"base",children:[(0,t.jsx)(n.span,{className:"strut",style:{height:"0.6944em"}}),(0,t.jsx)(n.span,{className:"mord",children:"2\u02c6"}),(0,t.jsx)(n.span,{className:"mord mathnormal",children:"n"})]})})]}),", where ",(0,t.jsxs)(n.span,{className:"katex",children:[(0,t.jsx)(n.span,{className:"katex-mathml",children:(0,t.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,t.jsxs)(n.semantics,{children:[(0,t.jsx)(n.mrow,{children:(0,t.jsx)(n.mi,{children:"n"})}),(0,t.jsx)(n.annotation,{encoding:"application/x-tex",children:"n"})]})})}),(0,t.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,t.jsxs)(n.span,{className:"base",children:[(0,t.jsx)(n.span,{className:"strut",style:{height:"0.4306em"}}),(0,t.jsx)(n.span,{className:"mord mathnormal",children:"n"})]})})]})," is the level in the U_net, starting from 0 in the upmost layer and 2 in the lowest layer."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"self.up_layer:"})," (int : [0-4]) Number indicating the layer in which the network is divided into Feature Extractor and Classifier."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"self.bilinear:"})," (Boolean) Boolean indicating the method for upsampling in the expanding path. ",(0,t.jsx)(n.em,{children:"Default"})," is True."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"self.n_classes:"})," (int) Number of classes in which the images will be classified. ",(0,t.jsx)(n.em,{children:"Default"})," is 2."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"self.attention:"})," (Boolean) Boolean to indicate if attention gates will be added on the upsampling step. ",(0,t.jsx)(n.em,{children:"Default"})," is False."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"self.resunet:"})," (Boolean) Boolean used to indicate if the double convolution will have a residual connection or not. ",(0,t.jsx)(n.em,{children:"Default"})," is False."]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"methods-1",children:"Methods"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"forward:"})," Function to perform the forward calculation of the logits. It takes as an input both the features extracted in ",(0,t.jsx)(n.a,{href:"###FE",children:"FE"})," and the feature maps extracted from the downsampling steps which can be obtained with the ",(0,t.jsx)(n.a,{href:"####methods",children:"DownSteps"}),"  method."]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"source-code-1",children:"Source code"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"class C(nn.Module):\n    def __init__(self, n_channels, starter, up_layer, bilinear = True, n_classes = 2, attention = False, resunet = False):\n        super(C, self).__init__()\n\n        self.n_channels = n_channels\n        self.bilinear = bilinear\n        self.starter = starter\n        self.up_layer = up_layer\n        self.n_classes = n_classes\n        self.attention = attention\n        self.resunet = resunet\n\n        factor = 2 if bilinear else 1\n\n        if self.up_layer == 0:\n            self.up1 = (Up(self.starter*(2**4), self.starter*(2**3) // factor, bilinear, attention, resunet = self.resunet))\n            self.up2 = (Up(self.starter*(2**3), self.starter*(2**2) // factor, bilinear, attention, resunet = self.resunet))\n            self.up3 = (Up(self.starter*(2**2), self.starter*(2**1) // factor, bilinear, attention, resunet = self.resunet))\n            self.up4 = (Up(self.starter*(2**1), self.starter, bilinear, attention, self.resunet))\n            self.outc = (OutConv(self.starter, n_classes))\n        elif self.up_layer == 1:\n            self.up2 = (Up(self.starter*(2**3), self.starter*(2**2) // factor, bilinear, attention, resunet = self.resunet))\n            self.up3 = (Up(self.starter*(2**2), self.starter*(2**1) // factor, bilinear, attention, resunet = self.resunet))\n            self.up4 = (Up(self.starter*(2**1), self.starter, bilinear, attention, resunet = self.resunet))\n            self.outc = (OutConv(self.starter, n_classes))\n        elif self.up_layer == 2:\n            self.up3 = (Up(self.starter*(2**2), self.starter*(2**1) // factor, bilinear, attention, resunet = self.resunet))\n            self.up4 = (Up(self.starter*(2**1), self.starter, bilinear, attention, resunet = self.resunet))\n            self.outc = (OutConv(self.starter, n_classes))\n        elif self.up_layer == 3:\n            self.up4 = (Up(self.starter*(2**1), self.starter, bilinear, attention, resunet = self.resunet))\n            self.outc = (OutConv(self.starter, n_classes))\n        elif self.up_layer == 4:\n            self.outc = (OutConv(self.starter, n_classes))\n\n\n    def forward(self, x, dw):\n        # Downsample steps\n        x1, x2, x3, x4, x5 = dw\n\n        # Upsampling steps\n        if self.up_layer == 0:\n            x = self.up1(x5, x4)\n            x = self.up2(x, x3)\n            x = self.up3(x, x2)\n            x = self.up4(x, x1)\n            logits = self.outc(x)\n        elif self.up_layer == 1:\n            x = self.up2(x, x3)\n            x = self.up3(x, x2)\n            x = self.up4(x, x1)\n            logits = self.outc(x)\n        elif self.up_layer == 2:\n            x = self.up3(x, x2)\n            x = self.up4(x, x1)\n            logits = self.outc(x)\n        elif self.up_layer == 3:\n            x = self.up4(x, x1)\n            logits = self.outc(x)\n        elif self.up_layer == 4:\n            logits = self.outc(x)\n\n        return logits\n"})}),"\n",(0,t.jsx)(n.h3,{id:"d",children:"D"}),"\n",(0,t.jsxs)(n.p,{children:["Class containing the layers used to discriminate between the source and target domain using the features extracted in ",(0,t.jsx)(n.a,{href:"###FE",children:"FE"}),"."]}),"\n",(0,t.jsxs)(n.p,{children:["The discriminator first downsamples the features using the same class ",(0,t.jsx)(n.a,{href:"./BuildingBlocks#Down",children:"Down"})," used in the contracting path of the U-Net. Then, a ",(0,t.jsx)(n.a,{href:"./BuildingBlocks#outdisc",children:"fully connected layer"})," is used to discriminate between source and target domain."]}),"\n",(0,t.jsx)(n.h4,{id:"attributes-2",children:"Attributes"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"self.initial_features:"})," (int) Number of features that will go into the final fully connected layer."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"self.starter:"})," (int) Number of feature maps obtained from the first double convolution performed. The number of feature maps obtained for every double convolution will be then calculated multiplying this value by ",(0,t.jsxs)(n.span,{className:"katex",children:[(0,t.jsx)(n.span,{className:"katex-mathml",children:(0,t.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,t.jsxs)(n.semantics,{children:[(0,t.jsxs)(n.mrow,{children:[(0,t.jsx)(n.mn,{children:"2"}),(0,t.jsx)(n.mtext,{children:"\u02c6"}),(0,t.jsx)(n.mi,{children:"n"})]}),(0,t.jsx)(n.annotation,{encoding:"application/x-tex",children:"2\u02c6n"})]})})}),(0,t.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,t.jsxs)(n.span,{className:"base",children:[(0,t.jsx)(n.span,{className:"strut",style:{height:"0.6944em"}}),(0,t.jsx)(n.span,{className:"mord",children:"2\u02c6"}),(0,t.jsx)(n.span,{className:"mord mathnormal",children:"n"})]})})]}),", where ",(0,t.jsxs)(n.span,{className:"katex",children:[(0,t.jsx)(n.span,{className:"katex-mathml",children:(0,t.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,t.jsxs)(n.semantics,{children:[(0,t.jsx)(n.mrow,{children:(0,t.jsx)(n.mi,{children:"n"})}),(0,t.jsx)(n.annotation,{encoding:"application/x-tex",children:"n"})]})})}),(0,t.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,t.jsxs)(n.span,{className:"base",children:[(0,t.jsx)(n.span,{className:"strut",style:{height:"0.4306em"}}),(0,t.jsx)(n.span,{className:"mord mathnormal",children:"n"})]})})]})," is the level in the U_net, starting from 0 in the upmost layer and 2 in the lowest layer."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"self.up_layer:"})," (int : [0-4]) Number indicating the layer in which the network is divided into Feature Extractor and Classifier."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"self.bilinear:"})," (Boolean) Boolean indicating the method for upsampling in the expanding path. ",(0,t.jsx)(n.em,{children:"Default"})," is True."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"self.resunet:"})," (Boolean) Boolean used to indicate if the double convolution will have a residual connection or not. ",(0,t.jsx)(n.em,{children:"Default"})," is False."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"self.grad_rev_w:"})," (float) Number with the learning weight of the discriminator head. ",(0,t.jsx)(n.em,{children:"Default"})," is 1."]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"methods-2",children:"Methods"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"forward:"})," Function to perform the forward calculation of the logits. This function takes the features extracted from ",(0,t.jsx)(n.a,{href:"#FE",children:"FE"})," and the value of grad_rev_w, which is the same as constant ",(0,t.jsxs)(n.span,{className:"katex",children:[(0,t.jsx)(n.span,{className:"katex-mathml",children:(0,t.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,t.jsxs)(n.semantics,{children:[(0,t.jsx)(n.mrow,{children:(0,t.jsx)(n.mi,{children:"\u03bb"})}),(0,t.jsx)(n.annotation,{encoding:"application/x-tex",children:"\\lambda"})]})})}),(0,t.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,t.jsxs)(n.span,{className:"base",children:[(0,t.jsx)(n.span,{className:"strut",style:{height:"0.6944em"}}),(0,t.jsx)(n.span,{className:"mord mathnormal",children:"\u03bb"})]})})]})," from ",(0,t.jsx)(n.a,{href:"./BuildingBlocks#gradreverse",children:"GradReverse"}),"."]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"source-code-2",children:"Source code"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"class D(nn.Module):\n    def __init__(self, initial_features, bilinear=True, starter = 8, up_layer = 3, resunet = False, grad_rev_w = 1):\n        super(D, self).__init__()\n\n        self.initial_features = initial_features\n        self.bilinear = bilinear\n        self.starter = starter\n        self.up_layer = up_layer\n        self.resunet = resunet\n        self.grad_rev_w = grad_rev_w\n\n        factor = 2 if bilinear else 1\n\n        self.revgrad = GradReverse.grad_reverse\n        \n        self.outd = (OutDisc(self.initial_features, 256))\n\n        if self.up_layer > 0:\n            self.down4_D = (Down(self.starter*(2**3)//factor, self.starter*(2**4)//factor, resunet = self.resunet))\n        if self.up_layer > 1:\n            self.down3_D = (Down(self.starter*(2**2)//factor, self.starter*(2**3)//factor, resunet = self.resunet))\n        if self.up_layer > 2:\n            self.down2_D = (Down(self.starter*(2**1)//factor, self.starter*(2**2)//factor, resunet = self.resunet))\n        if self.up_layer > 3:\n            self.down1_D = (Down(self.starter, self.starter*2//factor, resunet = self.resunet))\n            \n    def forward(self, x, grad_rev_w):\n\n        x = self.revgrad(x, grad_rev_w)\n\n        if self.up_layer == 1:\n            x = self.down4_D(x)\n        if self.up_layer == 2:\n            x = self.down3_D(x)\n            x = self.down4_D(x)\n        if self.up_layer == 3:\n            x = self.down2_D(x)\n            x = self.down3_D(x)\n            x = self.down4_D(x)\n        if self.up_layer == 4:\n            x = self.down1_D(x)\n            x = self.down2_D(x)\n            x = self.down3_D(x)\n            x = self.down4_D(x)\n\n        x = self.outd(x)\n\n        return x\n"})}),"\n",(0,t.jsx)(n.h2,{id:"networks-implemented",children:"Networks implemented"}),"\n",(0,t.jsx)(n.h3,{id:"unet",children:"UNet"}),"\n",(0,t.jsxs)(n.p,{children:["Class containing the layers used to create the custom UNet used to segment 2D images. An overview of the network can be seen ",(0,t.jsx)(n.a,{href:"#overview",children:"here"}),"."]}),"\n",(0,t.jsx)(n.h4,{id:"overview",children:"Overview"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"UnetDANN",src:s(7651).Z+"",width:"3968",height:"3100"})}),"\n",(0,t.jsx)(n.h4,{id:"attributes-3",children:"Attributes"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"self.n_channels:"})," (int) Number of channels [bands] on the images that will enter the network."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"self.n_classes:"})," (int) Number of classes in which the images will be classified."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"self.bilinear:"})," (Boolean) Boolean indicating the method for upsampling in the expanding path. ",(0,t.jsx)(n.em,{children:"Default"})," is True."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"self.starter:"})," (int) Number of feature maps obtained from the first double convolution performed. The number of feature maps obtained for every double convolution will be then calculated multiplying this value by ",(0,t.jsxs)(n.span,{className:"katex",children:[(0,t.jsx)(n.span,{className:"katex-mathml",children:(0,t.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,t.jsxs)(n.semantics,{children:[(0,t.jsxs)(n.mrow,{children:[(0,t.jsx)(n.mn,{children:"2"}),(0,t.jsx)(n.mtext,{children:"\u02c6"}),(0,t.jsx)(n.mi,{children:"n"})]}),(0,t.jsx)(n.annotation,{encoding:"application/x-tex",children:"2\u02c6n"})]})})}),(0,t.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,t.jsxs)(n.span,{className:"base",children:[(0,t.jsx)(n.span,{className:"strut",style:{height:"0.6944em"}}),(0,t.jsx)(n.span,{className:"mord",children:"2\u02c6"}),(0,t.jsx)(n.span,{className:"mord mathnormal",children:"n"})]})})]}),", where ",(0,t.jsxs)(n.span,{className:"katex",children:[(0,t.jsx)(n.span,{className:"katex-mathml",children:(0,t.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,t.jsxs)(n.semantics,{children:[(0,t.jsx)(n.mrow,{children:(0,t.jsx)(n.mi,{children:"n"})}),(0,t.jsx)(n.annotation,{encoding:"application/x-tex",children:"n"})]})})}),(0,t.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,t.jsxs)(n.span,{className:"base",children:[(0,t.jsx)(n.span,{className:"strut",style:{height:"0.4306em"}}),(0,t.jsx)(n.span,{className:"mord mathnormal",children:"n"})]})})]})," is the level in the U_net, starting from 0 in the upmost layer and 2 in the lowest layer. ",(0,t.jsx)(n.em,{children:"Default"})," is 8."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"self.up_layer:"})," (int : [0-4]) Number indicating the layer in which the network is divided into Feature Extractor and Classifier. ",(0,t.jsx)(n.em,{children:"Default"})," is 3."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"self.attention:"})," (Boolean) Boolean to indicate if attention gates will be added on the upsampling step. ",(0,t.jsx)(n.em,{children:"Default"})," is False."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"self.resunet:"})," (Boolean) Boolean used to indicate if the double convolution will have a residual connection or not. ",(0,t.jsx)(n.em,{children:"Default"})," is False."]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"methods-3",children:"Methods"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"forward:"})," Function to perform the forward calculation of the logits per class using images as an input."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"init_weights:"})," Function to initialize the weights using the xavier normal method."]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"source-code-3",children:"Source code"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"class UNet(nn.Module):\n    def __init__(self, n_channels, n_classes, bilinear=True, starter = 8, up_layer = 3, attention = False, resunet = False):\n\n        super(UNet, self).__init__()\n\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.bilinear = bilinear\n        self.starter = starter\n        self.up_layer = up_layer\n        self.attention = attention\n        self.resunet = resunet\n\n        self.FE = (FE(self.n_channels, self.starter, self.up_layer, self.bilinear, self.attention, resunet = self.resunet))\n        self.C = (C(self.n_channels, self.starter, self.up_layer, self.bilinear, self.n_classes, self.attention, resunet = self.resunet))\n\n        self.apply(self._init_weights)\n\n    def forward(self, x):\n\n        features = self.FE(x) # Feature extractor\n        down_st = self.FE.DownSteps(x) # Get channels that will be concatenated from downward steps\n\n        logits = self.C(features, down_st) # Classifier\n        \n        return logits\n\n\n    def _init_weights(self, module):\n        if isinstance(module, nn.Conv2d):\n            nn.init.xavier_normal_(module.weight)\n            if module.bias is not None:\n                module.bias.data.zero_()\n"})}),"\n",(0,t.jsx)(n.h3,{id:"unetdann",children:"UNetDANN"}),"\n",(0,t.jsxs)(n.p,{children:["Class containing the layers used to create the custom UNet-DANN network used to perform domain adaptation for sementing 2D images. This network uses the gradient reversal proposed by ",(0,t.jsx)(n.a,{href:"https://jmlr.org/papers/volume17/15-239/15-239.pdf",children:"Ganin et al. (2016)"})," on the ",(0,t.jsx)(n.a,{href:"#unet",children:"U-Net"})," semantic segmentation model."]}),"\n",(0,t.jsx)(n.h4,{id:"overview-1",children:"Overview"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"UnetDANN",src:s(6912).Z+"",width:"4900",height:"3104"})}),"\n",(0,t.jsx)(n.h4,{id:"attributes-4",children:"Attributes"}),"\n",(0,t.jsx)(n.h4,{id:"methods-4",children:"Methods"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"forward:"})," Function to perform the forward calculation of the logits per class and the logits per domain using images as an input. This networks has two heads, therefore it returns two results."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"init_weights:"})," Function to initialize the weights using the xavier normal method."]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"source-code-4",children:"Source code"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"class UNetDANN(nn.Module):\n    def __init__(self, n_channels, n_classes, bilinear=True, starter = 8, up_layer = 3, attention = False, resunet = False, DA = False, in_feat = None, grad_rev_w = 1):\n\n        super(UNetDANN, self).__init__()\n\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.bilinear = bilinear\n        self.starter = starter\n        self.up_layer = up_layer\n        self.attention = attention\n        self.resunet = resunet\n        self.in_feat = in_feat\n        self.DA = DA\n\n        self.FE = (FE(self.n_channels, self.starter, self.up_layer, self.bilinear, self.attention, resunet = self.resunet))\n        self.C = (C(self.n_channels, self.starter, self.up_layer, self.bilinear, self.n_classes, self.attention, resunet = self.resunet))\n\n        if DA:\n            self.D = (D(initial_features=self.in_feat, bilinear = self.bilinear, starter = self.starter, up_layer = self.up_layer, resunet = self.resunet, grad_rev_w = grad_rev_w))\n\n        self.apply(self._init_weights)\n\n    def forward(self, x, grad_rev_w = 0):\n\n        features = self.FE(x) # Feature extractor\n        down_st = self.FE.DownSteps(x) # Get channels that will be concatenated from downward steps\n\n        logits = self.C(features, down_st) # Classifier\n\n        dom_preds = self.D(features, grad_rev_w)\n\n        return logits, dom_preds\n\n\n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            nn.init.xavier_normal_(module.weight)\n        if isinstance(module, nn.Conv2d):\n            nn.init.xavier_normal_(module.weight)\n            if module.bias is not None:\n                module.bias.data.zero_()\n"})})]})}function h(e={}){const{wrapper:n}={...(0,l.a)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},7549:(e,n,s)=>{s.d(n,{Z:()=>t});const t=s.p+"assets/images/MajorBlocks-870f13becf67378cac0b6d5504642408.png"},7651:(e,n,s)=>{s.d(n,{Z:()=>t});const t=s.p+"assets/images/U_Net-68dd6bdc402edfa841f0051fb3da2aa1.png"},6912:(e,n,s)=>{s.d(n,{Z:()=>t});const t=s.p+"assets/images/U_Net_DANN-0a65ec189e807a52ec3d713d68373b4b.png"},1151:(e,n,s)=>{s.d(n,{Z:()=>a,a:()=>i});var t=s(7294);const l={},r=t.createContext(l);function i(e){const n=t.useContext(r);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(l):e.components||l:i(e.components),t.createElement(r.Provider,{value:n},e.children)}}}]);